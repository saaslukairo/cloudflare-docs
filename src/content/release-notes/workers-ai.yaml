---
link: "/workers-ai/changelog/"
productName: Workers AI
productLink: "/workers-ai/"
entries:
  - publish_date: "2025-11-13"
    title: Qwen3 LLM and Embeddings available on Workers AI
    description: |-
      - [`@cf/qwen/qwen3-30b-a3b-fp8`](/workers-ai/models/qwen3-30b-a3b-fp8/) and [`@cf/qwen/qwen3-embedding-0.6b`](/workers-ai/models/qwen3-embedding-0.6b) now available on Workers AI
  - publish_date: "2025-10-21"
    title: New voice and LLM models on Workers AI
    description: |-
      - Deepgram Aura 2 brings new text-to-speech capabilities to Workers AI. Check out [`@cf/deepgram/aura-2-en`](/workers-ai/models/aura-2-en/) and [`@cf/deepgram/aura-2-es`](/workers-ai/models/aura-2-es/) on how to use the new models.
      - IBM Granite model is also up! This new LLM model is small but mighty, take a look at the docs for more [`@cf/ibm-granite/granite-4.0-h-micro`](/workers-ai/models/granite-4.0-h-micro/)
  - publish_date: "2025-10-02"
    title: Deepgram Flux now available on Workers AI
    description: |-
      - We're excited to be a launch partner with Deepgram and offer their new Speech Recognition model built specifically for enabling voice agents. Check out [Deepgram's blog](https://deepgram.com/flux) for more details on the release.
      - Access the model through [`@cf/deepgram/flux`](/workers-ai/models/flux/) and check out the [changelog](/changelog/2025-10-02-deepgram-flux/) for in-depth examples.
  - publish_date: "2025-09-24"
    title: New local models available on Workers AI
    description: |-
      - We've added support for some regional models on Workers AI in support of uplifting local AI labs and AI sovereignty. Check out the [full blog post here](https://blog.cloudflare.com/sovereign-ai-and-choice).
      - [`@cf/pfnet/plamo-embedding-1b`](/workers-ai/models/plamo-embedding-1b) creates embeddings from Japanese text.
      - [`@cf/aisingapore/gemma-sea-lion-v4-27b-it`](/workers-ai/models/gemma-sea-lion-v4-27b-it) is a fine-tuned model that supports multiple South East Asian languages, including Burmese, English, Indonesian, Khmer, Lao, Malay, Mandarin, Tagalog, Tamil, Thai, and Vietnamese.
      - [`@cf/ai4bharat/indictrans2-en-indic-1B`](/workers-ai/models/indictrans2-en-indic-1B) is a translation model that can translate between 22 indic languages, including Bengali, Gujarati, Hindi, Tamil, Sanskrit and even traditionally low-resourced languages like Kashmiri, Manipuri and Sindhi. 
  - publish_date: "2025-09-23"
    title: 'New document formats supported by Markdown conversion utility'
    description: |-
      - Our [Markdown conversion utility](/workers-ai/features/markdown-conversion/) now supports converting `.docx` and `.odt` files.
  - publish_date: "2025-09-18"
    title: Model Catalog updates (types, EmbeddingGemma, model deprecation)
    description: |-
      - Workers AI types got updated in the upcoming wrangler release, please use `npm i -D wrangler@latest` to update your packages.
      - EmbeddingGemma model accuracy has been improved, we recommend re-indexing data to take advantage of the improved accuracy
      - Some older Workers AI models are being deprecated on October 1st, 2025. We reccommend you use the newer models such as [Llama 4](/workers-ai/models/llama-4-scout-17b-16e-instruct/) and [gpt-oss](/workers-ai/models/gpt-oss-120b/). The following models are being deprecated:
        - @hf/thebloke/zephyr-7b-beta-awq
        - @hf/thebloke/mistral-7b-instruct-v0.1-awq
        - @hf/thebloke/llama-2-13b-chat-awq
        - @hf/thebloke/openhermes-2.5-mistral-7b-awq
        - @hf/thebloke/neural-chat-7b-v3-1-awq
        - @hf/thebloke/llamaguard-7b-awq
        - @hf/thebloke/deepseek-coder-6.7b-base-awq
        - @hf/thebloke/deepseek-coder-6.7b-instruct-awq
        - @cf/deepseek-ai/deepseek-math-7b-instruct
        - @cf/openchat/openchat-3.5-0106
        - @cf/tiiuae/falcon-7b-instruct
        - @cf/thebloke/discolm-german-7b-v1-awq
        - @cf/qwen/qwen1.5-0.5b-chat
        - @cf/qwen/qwen1.5-7b-chat-awq
        - @cf/qwen/qwen1.5-14b-chat-awq
        - @cf/tinyllama/tinyllama-1.1b-chat-v1.0
        - @cf/qwen/qwen1.5-1.8b-chat
        - @hf/nexusflow/starling-lm-7b-beta
        - @cf/fblgit/una-cybertron-7b-v2-bf16
  - publish_date: "2025-09-05"
    title: Introducing EmbeddingGemma from Google
    description: |-
      - Weâ€™re excited to be a launch partner alongside Google to bring their newest embedding model to Workers AI. We're excited to introduce EmbeddingGemma delivers best-in-class performance for its size, enabling RAG and semantic search use cases. Take a look at [`@cf/google/embeddinggemma-300m`](/workers-ai/models/embeddinggemma-300m) for more details. Now available to use for embedding in AI Search too.
  - publish_date: "2025-08-27"
    title: Introducing Partner models to the Workers AI catalog
    description: |-
      - Read the [blog](https://blog.cloudflare.com/workers-ai-partner-models) for more details
      - [`@cf/deepgram/aura-1`](/workers-ai/models/aura-1) is a text-to-speech model that allows you to input text and have it come to life in a customizable voice
      - [`@cf/deepgram/nova-3`](/workers-ai/models/nova-3) is speech-to-text model that transcribes multilingual audio at a blazingly fast speed
      - [`@cf/pipecat-ai/smart-turn-v2`](/workers-ai/models/smart-turn-v2) helps you detect when someone is done speaking
      - [`@cf/leonardo/lucid-origin`](/workers-ai/models/lucid-origin) is a text-to-image model that generates images with sharp graphic design, stunning full-HD renders, or highly specific creative direction
      - [`@cf/leonardo/phoenix-1.0`](/workers-ai/models/phoenix-1.0) is a text-to-image model with exceptional prompt adherence and coherent text
      - WebSocket support added for audio models like `@cf/deepgram/aura-1`, `@cf/deepgram/nova-3`, `@cf/pipecat-ai/smart-turn-v2`
  - publish_date: "2025-08-05"
    title: Adding gpt-oss models to our catalog
    description: |-
      - Check out the [blog](https://blog.cloudflare.com/openai-gpt-oss-on-workers-ai) for more details about the new models
      - Take a look at the [`gpt-oss-120b`](/workers-ai/models/gpt-oss-120b) and [`gpt-oss-20b`](/workers-ai/models/gpt-oss-20b) model pages for more information about schemas, pricing, and context windows
  - publish_date: "2025-04-09"
    title: Pricing correction for @cf/myshell-ai/melotts
    description: |-
      - We've updated our documentation to reflect the correct pricing for melotts: $0.0002 per audio minute, which is actually cheaper than initially stated. The documented pricing was incorrect, where it said users would be charged based on input tokens.
  - publish_date: "2025-03-17"
    title: Minor updates to the model schema for llama-3.2-1b-instruct, whisper-large-v3-turbo, llama-guard
    description: |-
      - [llama-3.2-1b-instruct](/workers-ai/models/llama-3.2-1b-instruct/) - updated context window to the accurate 60,000
      - [whisper-large-v3-turbo](/workers-ai/models/whisper-large-v3-turbo/) - new hyperparameters available
      - [llama-guard-3-8b](/workers-ai/models/llama-guard-3-8b/) - the messages array must alternate between `user` and `assistant` to function correctly
  - publish_date: "2025-02-21"
    title: Workers AI bug fixes
    description: |-
      - We fixed a bug where `max_tokens` defaults were not properly being respected - `max_tokens` now correctly defaults to `256` as displayed on the model pages. Users relying on the previous behaviour may observe this as a breaking change. If you want to generate more tokens, please set the `max_tokens` parameter to what you need.
      - We updated model pages to show context windows - which is defined as the tokens used in the prompt + tokens used in the response. If your prompt + response tokens exceed the context window, the request will error. Please set `max_tokens` accordingly depending on your prompt length and the context window length to ensure a successful response.
  - publish_date: "2024-09-26"
    title: Workers AI Birthday Week 2024 announcements
    description: |-
      - Meta Llama 3.2 1B, 3B, and 11B vision is now available on Workers AI
      - `@cf/black-forest-labs/flux-1-schnell` is now available on Workers AI
      - Workers AI is fast! Powered by new GPUs and optimizations, you can expect faster inference on Llama 3.1, Llama 3.2, and FLUX models.
      - No more neurons. Workers AI is moving towards [unit-based pricing](/workers-ai/platform/pricing)
      - Model pages get a refresh with better documentation on parameters, pricing, and model capabilities
      - Closed beta for our Run Any* Model feature, [sign up here](https://forms.gle/h7FcaTF4Zo5dzNb68)
      - Check out the [product announcements blog post](https://blog.cloudflare.com/workers-ai) for more information
      - And the [technical blog post](https://blog.cloudflare.com/workers-ai/making-workers-ai-faster) if you want to learn about how we made Workers AI fast

  - publish_date: "2024-07-23"
    title: Meta Llama 3.1 now available on Workers AI
    description: |-
      Workers AI now suppoorts [Meta Llama 3.1](/workers-ai/models/llama-3.1-8b-instruct/).

  - publish_date: "2024-07-11"
    title: New community-contributed tutorial
    description: |-
      - Added community contributed tutorial on how to [create APIs to recommend products on e-commerce sites using Workers AI and Stripe](https://web.archive.org/web/20250714161553/https://developers.cloudflare.com/developer-spotlight/tutorials/creating-a-recommendation-api/).

  - publish_date: "2024-06-27"
    title: Introducing embedded function calling
    description: |-
      - A new way to do function calling with [Embedded function calling](/workers-ai/function-calling/embedded)
      - Published new [`@cloudflare/ai-utils`](https://www.npmjs.com/package/@cloudflare/ai-utils) npm package
      - Open-sourced [`ai-utils on Github`](https://github.com/cloudflare/ai-utils)

  - publish_date: "2024-06-19"
    title: Added support for traditional function calling
    description: |-
      - [Function calling](/workers-ai/function-calling/) is now supported on enabled models
      - Properties added on [models](/workers-ai/models/) page to show which models support function calling

  - publish_date: "2024-06-18"
    title: Native support for AI Gateways
    description: |-
      Workers AI now natively supports [AI Gateway](/ai-gateway/usage/providers/workersai/#worker).

  - publish_date: "2024-06-11"
    title: Deprecation announcement for `@cf/meta/llama-2-7b-chat-int8`
    description: |-
      We will be deprecating `@cf/meta/llama-2-7b-chat-int8` on 2024-06-30.

      Replace the model ID in your code with a new model of your choice:
      - [`@cf/meta/llama-3-8b-instruct`](/workers-ai/models/llama-3-8b-instruct/) is the newest model in the Llama family (and is currently free for a limited time on Workers AI).
      - [`@cf/meta/llama-3-8b-instruct-awq`](/workers-ai/models/llama-3-8b-instruct-awq/) is the new Llama 3 in a similar precision to your currently selected model. This model is also currently free for a limited time.

      If you do not switch to a different model by June 30th, we will automatically start returning inference from `@cf/meta/llama-3-8b-instruct-awq`.

  - publish_date: "2024-05-29"
    title: Add new public LoRAs and note on LoRA routing
    description: |-
      * Added documentation on [new public LoRAs](/workers-ai/fine-tunes/public-loras/).
      * Noted that you can now run LoRA inference with the base model rather than explicitly calling the `-lora` version

  - publish_date: "2024-05-17"
    title: Add OpenAI compatible API endpoints
    description: |-
      Added OpenAI compatible API endpoints for `/v1/chat/completions` and `/v1/embeddings`. For more details, refer to [Configurations](/workers-ai/configuration/open-ai-compatibility/).

  - publish_date: "2024-04-11"
    title: Add AI native binding
    description: |-
      * Added new AI native binding, you can now run models with `const resp = await env.AI.run(modelName, inputs)`
      * Deprecated `@cloudflare/ai` npm package. While existing solutions using the @cloudflare/ai package will continue to work, no new Workers AI features will be supported.
        Moving to native AI bindings is highly recommended
