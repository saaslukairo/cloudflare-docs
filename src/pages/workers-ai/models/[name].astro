---
import type { GetStaticPaths, MarkdownHeading } from "astro";
import { getCollection } from "astro:content";
import StarlightPage, {
	type StarlightPageProps,
} from "@astrojs/starlight/components/StarlightPage.astro";
import { LinkButton, Tabs, TabItem, Code, Aside, Badge } from "~/components";
import ModelInfo from "~/components/models/ModelInfo.tsx";
import ModelFeatures from "~/components/models/ModelFeatures.tsx";
import SchemaViewer from "~/components/models/SchemaViewer.astro";

import TextGenerationCode from "~/components/models/code/TextGenerationCode.astro";
import AutomaticSpeechRecognitionCode from "~/components/models/code/AutomaticSpeechRecognitionCode.astro";
import ImageClassificationCode from "~/components/models/code/ImageClassificationCode.astro";
import ImageToTextCode from "~/components/models/code/ImageToTextCode.astro";
import ObjectDetectionCode from "~/components/models/code/ObjectDetectionCode.astro";
import SummarizationCode from "~/components/models/code/SummarizationCode.astro";
import TextClassificationCode from "~/components/models/code/TextClassificationCode.astro";
import TextEmbeddingCode from "~/components/models/code/TextEmbeddingCode.astro";
import TextToImageCode from "~/components/models/code/TextToImageCode.astro";
import TranslationCode from "~/components/models/code/TranslationCode.astro";
import StableDiffusionV15Img2ImgCode from "~/components/models/code/StableDiffusion-v1-5-img2imgCode.astro";
import StableDiffusionV15InpaintingCode from "~/components/models/code/StableDiffusion-v1-5-inpaintingCode.astro";
import Flux1Schnell from "~/components/models/code/Flux-1-Schnell.astro";
import WhisperBase64Code from "~/components/models/code/WhisperBase64Code.astro";
import MelottsCode from "~/components/models/code/MelottsCode.astro";
import LlamaGuard from "~/components/models/code/LlamaGuard.astro";
import BgeRerankerBase from "~/components/models/code/Bge-Reranker-Base.astro";

import { authorData } from "~/components/models/data";
import OpenAIResponsesTextGenerationCode from "~/components/models/code/OpenAIResponsesTextGenerationCode.astro";
import DeepgramAura from "~/components/models/code/DeepgramAura.astro";
import DeepgramNova from "~/components/models/code/DeepgramNova.astro";
import DeepgramFlux from "~/components/models/code/DeepgramFlux.astro";

export const getStaticPaths = (async () => {
	const models = await getCollection("workers-ai-models");

	return models.map((entry) => {
		return {
			params: {
				name: entry.data.name.split("/")[2],
			},
			props: { model: entry.data },
		};
	});
}) satisfies GetStaticPaths;

const { name } = Astro.params;
const { model } = Astro.props;

let CodeExamples = null;
switch (model.task.name) {
	case "Text Generation":
		CodeExamples = TextGenerationCode;
		break;
	case "Automatic Speech Recognition":
		CodeExamples = AutomaticSpeechRecognitionCode;
		break;
	case "Image Classification":
		CodeExamples = ImageClassificationCode;
		break;
	case "Object Detection":
		CodeExamples = ObjectDetectionCode;
		break;
	case "Image-to-Text":
		CodeExamples = ImageToTextCode;
		break;
	case "Text-to-Image":
		CodeExamples = TextToImageCode;
		break;
	case "Translation":
		CodeExamples = TranslationCode;
		break;
	case "Summarization":
		CodeExamples = SummarizationCode;
		break;
	case "Text Embeddings":
		CodeExamples = TextEmbeddingCode;
		break;
	case "Text Classification":
		CodeExamples = TextClassificationCode;
		break;
}

// Overrides
if (model.name === "@cf/runwayml/stable-diffusion-v1-5-img2img") {
	CodeExamples = StableDiffusionV15Img2ImgCode;
}

if (model.name === "@cf/runwayml/stable-diffusion-v1-5-inpainting") {
	CodeExamples = StableDiffusionV15InpaintingCode;
}

if (model.name === "@cf/black-forest-labs/flux-1-schnell") {
	CodeExamples = Flux1Schnell;
}

if (model.name === "@cf/openai/whisper-large-v3-turbo") {
	CodeExamples = WhisperBase64Code;
}

if (model.name === "@cf/myshell-ai/melotts") {
	CodeExamples = MelottsCode;
}

if (model.name === "@cf/meta/llama-guard-3-8b") {
	CodeExamples = LlamaGuard;
}

if (model.name === "@cf/baai/bge-reranker-base") {
	CodeExamples = BgeRerankerBase;
}

if (
	model.name === "@cf/openai/gpt-oss-120b" ||
	model.name === "@cf/openai/gpt-oss-20b"
) {
	CodeExamples = OpenAIResponsesTextGenerationCode;
}

if (model.name === "@cf/deepgram/aura-1") {
	CodeExamples = DeepgramAura;
}

if (model.name === "@cf/deepgram/nova-3") {
	CodeExamples = DeepgramNova;
}

if (model.name === "@cf/deepgram/flux") {
	CodeExamples = DeepgramFlux;
}

const description = model.description;

const isBeta = model.properties.find(
	({ property_id, value }) => property_id === "beta" && value === "true",
);

let hasPlayground = model.task.name === "Text Generation";

// temporary workaround for playground limitations
if (model.name.includes("@cf/openai/gpt-oss")) {
	hasPlayground = false;
}

const author = (authorData as any)[model.name.split("/")[1]];

// Strong type coercion needed due to Starlight's component override for hideTitle
const starlightPageProps = {
	frontmatter: {
		title: name,
		description,
		pcx_content_type: "reference",
	},
	headings: [
		hasPlayground
			? { depth: 2, slug: "Playground", text: "Playground" }
			: false,
		CodeExamples ? { depth: 2, slug: "Usage", text: "Usage" } : false,
		{ depth: 2, slug: "Parameters", text: "Parameters" },
		{ depth: 3, slug: "Input", text: "Input" },
		{ depth: 3, slug: "Output", text: "Output" },
		{ depth: 2, slug: "API Schemas", text: "API Schemas" },
	].filter((v) => Boolean(v)) as MarkdownHeading[],
	hideTitle: true,
} as StarlightPageProps;
---

<StarlightPage {...starlightPageProps}>
	<div class="align-center flex">
		{
			author ? (
				<img
					class="mr-4 block h-12 w-12"
					src={author.logo}
					alt={`${author.name} logo`}
				/>
			) : (
				<div class="mr-4 flex h-12 w-12 items-center justify-center rounded-md bg-gray-100 text-2xl font-black text-gray-400 uppercase">
					{model.name.split("/")[1].substring(0, 1)}
				</div>
			)
		}
		<div>
			<h1
				id="_top"
				class="-mt-4! mb-0! flex items-center text-4xl! leading-none! font-bold!"
			>
				{name}
				{isBeta && <Badge text="Beta" variant="caution" class="mt-2 ml-3" />}
			</h1>
			<span class="-mt-1 block"><ModelInfo model={model} /></span>
		</div>
	</div>

	<span class="mt-4 block font-mono text-sm text-gray-400">{model.name}</span>

	<p class="mt-3 mb-2!">{description}</p>

	{
		model.name === "@cf/meta/llama-3.2-11b-vision-instruct" && (
			<Aside>
				<p>
					To use Llama 3.2 11b Vision Instruct, you need to agree to the{" "}
					<a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE">
						Meta License
					</a>{" "}
					and{" "}
					<a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md">
						Acceptable Use Policy
					</a>
					. To do so, please send an initial request to
					<code>@cf/meta/llama-3.2-11b-vision-instruct</code> with
					<code>"prompt" : "agree"</code>. After that, you'll be able to use the
					model as normal.
				</p>
				<Code
					code={`curl https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/run/@cf/meta/llama-3.2-11b-vision-instruct \\
   -X POST \\
   -H "Authorization: Bearer $CLOUDFLARE_AUTH_TOKEN" \\
   -d '{ "prompt": "agree"}'`}
					lang="sh"
				/>
			</Aside>
		)
	}

	{
		model.name === "@cf/deepgram/flux" && (
			<Aside>
				<p>
					For the month of October 2025, Deepgram's Flux model will be free to use on Workers AI. Official pricing will be announced soon and charged after the promotional pricing period ends on October 31, 2025.
				</p>
			</Aside>
		)
	}

	<ModelFeatures model={model} />
	{
		model.name === "@cf/deepgram/nova-3" && (
			<Aside>
				<p>
					The <a href="/workers-ai/platform/pricing">pricing of this model</a>{" "}
					is different based on transport. Transport-based pricing does not apply to all models.
				</p>
				<p>
					<ul>
						<li>
							WebSocket: $0.0092 per audio minute output (836.36 neurons per
							audio minute output)
						</li>
						<li>
							Regular HTTP: $0.0052 per audio minute output (472.73 neurons per
							audio minute output)
						</li>
					</ul>
				</p>
			</Aside>
		)
	}

	{
		hasPlayground && (
			<>
				<h2 id="Playground">Playground</h2>
				<p>
					Try out this model with Workers AI LLM Playground. It does not require
					any setup or authentication and an instant way to preview and test a
					model directly in the browser.
				</p>
				<LinkButton
					href={`https://playground.ai.cloudflare.com/?model=${model.name}`}
				>
					Launch the LLM Playground
				</LinkButton>
			</>
		)
	}

	{
		CodeExamples && (
			<>
				<h2 id="Usage">Usage</h2>
				<CodeExamples name={model.name} lora={false} />
			</>
		)
	}

	<h2 id="Parameters">Parameters</h2>
	<p><span class="text-red-500">*</span> indicates a required field</p>
	<h3 id="Input">Input</h3>
	<SchemaViewer schema={model.schema.input} />

	<h3 id="Output">Output</h3>
	{
		model.schema.output.format === "binary" ? (
			<>
				<p>
					The binding returns a <code>ReadableStream</code> with the image in
					JPEG or PNG format (check the model's output schema).
				</p>
			</>
		) : (
			<SchemaViewer schema={model.schema.output} />
		)
	}

	<h2 id="API Schemas">API Schemas</h2>
	<p>The following schemas are based on JSON Schema</p>

	<Tabs>
		<TabItem label="Input">
			<Code code={JSON.stringify(model.schema.input, null, 4)} lang="json" />
		</TabItem>
		<TabItem label="Output">
			<Code code={JSON.stringify(model.schema.output, null, 4)} lang="json" />
		</TabItem>
	</Tabs>
</StarlightPage>
